{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4381882-7b86-41e7-bfc8-0d3e0c537ceb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294496f9-74e1-4a5d-b4f0-bc614f4aeda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3a6bb-7268-4419-a63a-ae9cd8d73474",
   "metadata": {},
   "source": [
    "### Data Loading  \n",
    "- Keras accepts NumPy arrays, TensorFlow Datasets, and Python generators that yield batches of data\n",
    "- TF Datasets are most efficient in terms of async pre-processing on a GPU and prefetching data on GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed57d62c-76fb-4fcd-b762-4d0877742dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 100*np.random.rand(100000, 3)\n",
    "Y = np.zeros((100000, 2))\n",
    "for i in np.arange(len(X)):\n",
    "    if X[i,0] > 80 or X[i,1] > 80 or X[i,2] > 80: Y[i,0] = 1\n",
    "    else: Y[i,1] = 1\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y)).shuffle(len(Y)).batch(len(Y))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786c256-f485-4f7b-8390-d34f0ad7a7e7",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "- TextVectorization is a useful built-in for handling raw strings\n",
    "- Normalization is a useful built-in for normalizing features\n",
    "- Image handling classes also exist (CenterCrop, Rescaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f2e6b-2589-45f6-861a-d80b5f30f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "training_data = np.array([[\"This is the 1st sample test test.\"], [\"And here's the 2nd sample.\"]])\n",
    "vectorizer = TextVectorization(output_mode=\"int\")\n",
    "vectorizer.adapt(training_data)\n",
    "integer_data = vectorizer(training_data)\n",
    "print(integer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49c803-7ef6-4e50-9ea0-1bff73d32d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Normalization\n",
    "training_data = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(\"float32\")\n",
    "normalizer = Normalization(axis=-1)\n",
    "normalizer.adapt(training_data)\n",
    "normalized_data = normalizer(training_data)\n",
    "print(\"var: %.4f\" % np.var(normalized_data))\n",
    "print(\"mean: %.4f\" % np.mean(normalized_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e94db3-d4fb-45ba-bf49-b401e8a9108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import CenterCrop\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "training_data = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(\"float32\")\n",
    "cropper = CenterCrop(height=150, width=150)\n",
    "scaler = Rescaling(scale=1.0 / 255)\n",
    "output_data = scaler(cropper(training_data))\n",
    "print(\"shape:\", output_data.shape)\n",
    "print(\"min:\", np.min(output_data))\n",
    "print(\"max:\", np.max(output_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e178cf0-56cf-494e-b725-3b885a5a8454",
   "metadata": {},
   "source": [
    "### Building Models\n",
    "- A layer is an input-output transformation\n",
    "- Begin with a keras.Input() level\n",
    "  - Add .Rescaling(), etc. to preprocess\n",
    "  - Add .Dense(), etc. to train\n",
    "  - Combine into model\n",
    "- The below tests out an implementation with the dataset constructed above and fitted with model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74617f53-34d4-4755-9b60-ed526a7a8a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat Dataset Creation\n",
    "X = 100*np.random.rand(100000, 3)\n",
    "Y = np.zeros((100000, 2))\n",
    "for i in np.arange(len(X)):\n",
    "    if X[i,0] > 80 or X[i,1] > 80 or X[i,2] > 80: Y[i,0] = 1\n",
    "    else: Y[i,1] = 1\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y)).shuffle(len(Y)).batch(len(Y))\n",
    "dataset_training = \n",
    "dataset_testing = \n",
    "\n",
    "# Create Model\n",
    "inputs = keras.Input(shape=(3))\n",
    "xx = keras.layers.Dense(256, activation=\"relu\")(inputs)\n",
    "xx = keras.layers.Dense(128, activation=\"relu\")(xx)\n",
    "outputs = keras.layers.Dense(2, activation=\"softmax\")(xx)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.01), \n",
    "              loss=tf.losses.Huber(delta=0.5))\n",
    "\n",
    "# Fit the Model\n",
    "print(\"Fitting Model...\")\n",
    "model.fit(dataset,\n",
    "          batch_size = 1000,\n",
    "          epochs=100, \n",
    "          steps_per_epoch=2,\n",
    "          verbose=1)\n",
    "\n",
    "# Test the Model\n",
    "print(\"======================\")\n",
    "\n",
    "for i in np.arange(100):\n",
    "    test_x = 100*np.random.rand(1, 3)\n",
    "    test_y = np.zeros((1, 2))\n",
    "    if test_x[0,0] > 80 or test_x[0,1] > 80 or test_x[0,2] > 80: test_y[0,0] = 1\n",
    "    else: test_y[0,1] = 1\n",
    "    test_dat = tf.data.Dataset.from_tensor_slices(test_x).batch(1)\n",
    "    \n",
    "    print(test_x)\n",
    "    print(model.predict(test_dat))\n",
    "    print(test_y)\n",
    "    print(\"---------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fd1fd-8b18-4b1a-ab09-863f50f76c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
